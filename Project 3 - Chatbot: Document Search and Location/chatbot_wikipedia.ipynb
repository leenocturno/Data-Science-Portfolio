{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e6b651",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center; color: #1E90FF; font-size: 30px;\">DocuWiki Chatbot: Document Search and Location </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6140a",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [Import OpenAI, Test Connection & Embeddings](#1)\n",
    "* [Crawling Wikipedia & Generate PDFs)](#2)\n",
    "* [Text Chunk Dividing & Embedding)](#3)\n",
    "* [Testing with Questions](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cc0db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f188c8",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EAEAEA; padding: 0px; border-radius: 5px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"text-align: center; color: #333333; font-size: 20px; font-weight: bold;\", id=1>Import OpenAI, Test Connection & Embeddings</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY deleted\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b84744de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Li Feng!\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# Test connection\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"If the connection is valid, say 'Hello, Li Feng' to me.\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d80c84b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Length: 1536 \n",
      "Embedding snippet: [-0.0022081956267356873, -0.03175782039761543, -0.05779833719134331, -0.03731878846883774, 0.03745278716087341, -0.029859496280550957, -0.01409225258976221, -0.0009505570633336902, -0.011015853844583035, -0.041271764785051346]\n"
     ]
    }
   ],
   "source": [
    "# Test embeddings\n",
    "sample_text = \"Chopin is a great composer.\"\n",
    "embedding = client.embeddings.create(\n",
    "    model = \"text-embedding-3-small\",\n",
    "    input = sample_text\n",
    ")\n",
    "\n",
    "print(\"Embedding Length:\", len(embedding.data[0].embedding),\n",
    "      \"\\nEmbedding snippet:\", embedding.data[0].embedding[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7ed2c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EAEAEA; padding: 0px; border-radius: 5px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"text-align: center; color: #333333; font-size: 20px; font-weight: bold;\", id=2>Crawling Wikipedia & Generate PDF</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad42976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"High-intensity interval training\",\n",
    "    \"Sergei Rachmaninoff\"\n",
    "]\n",
    "\n",
    "def fetch_pdf_bytes(title):\n",
    "    \"\"\"Download the ready-made PDF from Wikipedia REST.\"\"\"\n",
    "    safe_title = quote(title, safe=\"\")\n",
    "    url = f\"https://en.wikipedia.org/api/rest_v1/page/pdf/{safe_title}\"\n",
    "    resp = requests.get(url, headers={'User-Agent': 'MyWikiBot/1.0'})\n",
    "    resp.raise_for_status()\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def save_pdf_from_bytes(pdf_bytes, output_path):\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(pdf_bytes)\n",
    "\n",
    "def sanitize_filename(title):\n",
    "    return re.sub(r\"[^\\w\\-_\\.]\", \"_\", title)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "    for title in titles:\n",
    "        try:\n",
    "            pdf = fetch_pdf_bytes(title)\n",
    "        except requests.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                print(f\"No PDF available for {title!r}, skipping.\")\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        fn = sanitize_filename(title) + \".pdf\"\n",
    "        save_pdf_from_bytes(pdf, os.path.join(\"output\", fn))\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text\n",
    "    return text\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "pdf_folder = os.path.join(base_dir, \"output\")\n",
    "pdf_texts = {}\n",
    "\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    path = os.path.join(pdf_folder, filename)\n",
    "    text = extract_text_from_pdf(path)\n",
    "    pdf_texts[filename] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97ac06",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EAEAEA; padding: 0px; border-radius: 5px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"text-align: center; color: #333333; font-size: 20px; font-weight: bold;\", id=3>Text Chunk Dividing & Embedding</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1e92da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 166\n",
      "Example chunk: ('High-intensity_interval_training.pdf', 'HIIT with dumbbells\\nHigh-intensity interval training\\nHigh-intensity interval training  (HIIT ) is a training\\nprotocol alternating short periods of intense or explosive\\nanaerobic exercise  with brief recovery periods until the point\\nof exhaustion.[1] HIIT  involves exercises performed in\\nrepeated quick bursts at maximum or near maximal effort\\nwith periods of rest or low activity between bouts. The very\\nhigh level of intensity , the interval duration, and number of\\nbouts distinguish it from aerobic  (cardiovascular) activity ,\\nbecause the body significantly recruits anaerobic energy\\nsystems (although not completely to the exclusion of aerobic\\npathways).[1] The method thereby relies on \"the anaerobic\\nenergy releasing system almost maximally\".[1]\\nAlthough there are varying forms of HIIT -style workouts\\nwhich may involve exercises associated with both\\ncardiovascular activity and also resistance training , HIIT\\'s crucial features of maximal effort, duration,\\nand short rest periods (thereby t')\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=1000, overlap=100):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunks.append(text[i:i+chunk_size])\n",
    "    return chunks\n",
    "\n",
    "all_chunks = []\n",
    "for filename, text in pdf_texts.items():\n",
    "    chunks = chunk_text(text)\n",
    "    for chunk in chunks:\n",
    "        all_chunks.append((filename, chunk))\n",
    "\n",
    "print(\"Total chunks created:\", len(all_chunks))\n",
    "print(\"Example chunk:\", all_chunks[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08337ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built with 166 vectors\n"
     ]
    }
   ],
   "source": [
    "# Chunk embedding\n",
    "embeddings = []\n",
    "metadatas = []\n",
    "\n",
    "for filename, chunk in all_chunks:\n",
    "    resp = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=chunk\n",
    "    )\n",
    "    emb = resp.data[0].embedding\n",
    "    embeddings.append(emb)\n",
    "    metadatas.append({\"source\": filename, \"text\": chunk})\n",
    "\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"Index built with\", index.ntotal, \"vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d954e3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EAEAEA; padding: 0px; border-radius: 5px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "    <h1 style=\"text-align: center; color: #333333; font-size: 20px; font-weight: bold;\", id=4>Testing with Questions</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faf0132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Sergei Rachmaninoff was born in the year 1873.\n",
      "Source: Sergei_Rachmaninoff.pdf | Location: chunk 50\n",
      "Source: Sergei_Rachmaninoff.pdf | Location: chunk 52\n"
     ]
    }
   ],
   "source": [
    "def answer_question(query, k=2):\n",
    "    resp = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=query\n",
    "    )\n",
    "    q_emb = np.array([resp.data[0].embedding]).astype(\"float32\")\n",
    "\n",
    "    D, I = index.search(q_emb, k)\n",
    "\n",
    "    context_chunks = []\n",
    "    sources = []\n",
    "    for idx in I[0]:\n",
    "        meta = metadatas[idx]\n",
    "        context_chunks.append(meta[\"text\"])\n",
    "        sources.append((meta[\"source\"], idx))\n",
    "\n",
    "    context = \"\\n\\n\".join(context_chunks)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer the question using only the provided context. If not in context, say 'Not found in the documents.'\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "\n",
    "    result = {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": [{\"document\": s[0], \"chunk_index\": s[1]} for s in sources]\n",
    "    }\n",
    "    return result\n",
    "\n",
    "query = \"In which year Sergei Rachmaninoff was born?\"\n",
    "result = answer_question(query, k=2)\n",
    "\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "for s in result[\"sources\"]:\n",
    "    print(f\"Source: {s['document']} | Location: chunk {s['chunk_index']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c18bcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: A 2019 clinical trial found that HIIT improved vascular health in inactive individuals, demonstrating decreases in arterial wall thickness and improved endothelial function. It was noted that HIIT had stronger effects compared to medium intensity continuous training in enhancing blood flow and vasodilation.\n",
      "Source: High-intensity_interval_training.pdf | Location: chunk 18\n",
      "Source: High-intensity_interval_training.pdf | Location: chunk 17\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you describe 1 research related to HIIT? Answer should be no more than 50 words. \"\n",
    "result = answer_question(query, k=2)\n",
    "\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "for s in result[\"sources\"]:\n",
    "    print(f\"Source: {s['document']} | Location: chunk {s['chunk_index']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semsearch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
